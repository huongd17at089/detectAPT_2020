{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sqn2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMskoJsftuCM+75EV5xfZKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huongd17at089/detectAPT_2020/blob/main/Sqn2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG184s0OgTh4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVXnWZ9EjzqH"
      },
      "source": [
        "data_folder  = \"/content/drive/My Drive/Graph2Vec/data/\"\n",
        "workers = 4\n",
        "wl_iterations = 2\n",
        "dimensions = 64\n",
        "min_count = 1\n",
        "down_sampling = 0.0001\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "output_path = \"/content/drive/My Drive/Graph2Vec/vectors/vector.csv\"\n",
        "# saved model \n",
        "# \"/content/drive/My Drive/Graph2Vec/model/model\" \n",
        "seve_model_path = \"/content/drive/My Drive/Graph2Vec/model/model1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um1bbr1CkmPA"
      },
      "source": [
        "def get_sequence(file_path):\n",
        "  name = file_path.strip(\".json\").split(\"/\")[-1]\n",
        "  data = json.load(open(file_path, encoding=\"utf8\"))\n",
        "  sequence = []\n",
        "  processes = data[\"Processes\"]\n",
        "  if processes:\n",
        "      incidents = data[\"Incidents\"]\n",
        "      process_dict = {}\n",
        "      for inc in incidents:\n",
        "          if inc[\"MitreAttacks\"] :\n",
        "              process_dict[inc[\"ProcessOID\"]] = process_dict.get(inc[\"ProcessOID\"], []) + inc[\"MitreAttacks\"]\n",
        "      processes = sorted(processes, key=lambda d: d[\"CreationTimestamp\"])\n",
        "      for p in processes:\n",
        "          sequence.append(\"-\".join(process_dict.get(p[\"OID\"], [\"none\"])))\n",
        "  return TaggedDocument(words=sequence, tags=[\"s_\" + name])\n",
        "  \n",
        "\n",
        "\n",
        "def save_to_csv(output_path, model, files, dimensions):\n",
        "  out = []\n",
        "  for f in files:\n",
        "      identifier = f.split(\"/\")[-1].strip(\".json\")\n",
        "      vector = [identifier] + list(model.docvecs[\"s_\"+identifier])\n",
        "      if(\"malware\" in identifier) :\n",
        "          vector  = vector  + [1]\n",
        "      else:\n",
        "          vector  = vector  + [0]\n",
        "      out.append(vector)\n",
        "  column_names = [\"id\"]+[\"x_\"+str(dim) for dim in range(dimensions)] + [\"label\"]\n",
        "  out = pd.DataFrame(out, columns=column_names)\n",
        "  out = out.sort_values([\"id\"])\n",
        "  out.to_csv(output_path, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_u2Isw8j2Tf"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from joblib import Parallel, delayed\n",
        "import glob\n",
        "from gensim.test.utils import get_tmpfile\n",
        "import os\n",
        "\n",
        "files = []\n",
        "for r, d, f in os.walk(data_folder):\n",
        "  for file in f:\n",
        "    if '.json' in file:\n",
        "      files.append(os.path.join(r, file))\n",
        "\n",
        "document_collections = Parallel(n_jobs=workers)(delayed(get_sequence)(f) for f in tqdm(files))\n",
        "\n",
        "model = Doc2Vec(document_collections,\n",
        "                    vector_size=dimensions,\n",
        "                    window=2,\n",
        "                    min_count=min_count,\n",
        "                    dm=1,\n",
        "                    sample=down_sampling,\n",
        "                    workers=workers,\n",
        "                    epochs=epochs,\n",
        "                    alpha=learning_rate\n",
        "                    )\n",
        "# fname = get_tmpfile(\"test_model\")\n",
        "model.save(seve_model_path)\n",
        "\n",
        "save_to_csv(output_path, model, files, dimensions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}